{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torchvision import utils\n",
    "from model_drum import Generator\n",
    "import sys\n",
    "sys.path.append('./melgan')\n",
    "from modules import Generator_melgan\n",
    "import os, random\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from vscode_audio import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LATENT = 512\n",
    "N_MLP = 8\n",
    "n_samples = 4\n",
    "\n",
    "SIZE_OUTPUT = 64 # size of output image\n",
    "\n",
    "# CHECKPOINT = \"./freesound_checkpoint.pt\"\n",
    "CHECKPOINT = \"./tmp/envs_210000.pt\"\n",
    "#CHECKPOINT = \"./tmp/beats_090000.pt\"\n",
    "DATAPATH = \"./data/freesound/\"\n",
    "\n",
    "#MELGAN_MODEL_NAME = \"mel_vocal_best_netG.pt\"\n",
    "MELGAN_MODEL_NAME = \"best_netG.pt\"\n",
    "\n",
    "\n",
    "\n",
    "STOREDZ_PATH = \"./tmp/stored_z.npz\"\n",
    "\n",
    "TRUNCATION = 1\n",
    "TRUNCATION_MEAN = 4096\n",
    "\n",
    "\n",
    "SR = 44100\n",
    "\n",
    "device_name = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "generator = Generator(SIZE_OUTPUT, N_LATENT, N_MLP, channel_multiplier=2).to(device_name)\n",
    "checkpoint = torch.load(CHECKPOINT, map_location=torch.device(device_name))\n",
    "\n",
    "generator.load_state_dict(checkpoint[\"g_ema\"], strict=False)\n",
    "\n",
    "\n",
    "if TRUNCATION < 1:\n",
    "    with torch.no_grad():\n",
    "        mean_latent = generator.mean_latent(TRUNCATION_MEAN)\n",
    "else:\n",
    "    mean_latent = None\n",
    "\n",
    "if os.path.exists(STOREDZ_PATH):\n",
    "    z_presets = np.load(STOREDZ_PATH)[\"z_presets\"]\n",
    "    assert z_presets.shape[0] == 4 and z_presets.shape[1] == N_LATENT\n",
    "else:\n",
    "    z_presets = np.random.randn(4, N_LATENT)\n",
    "    np.savez(STOREDZ_PATH, z_presets=z_presets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocoder(device_name):\n",
    "    feat_dim = 80\n",
    "    mean_fp = f'{DATAPATH}/mean.mel.npy'\n",
    "    std_fp = f'{DATAPATH}/std.mel.npy'\n",
    "    v_mean = torch.from_numpy(np.load(mean_fp)).float().view(1, feat_dim, 1).to(device_name)\n",
    "    v_std = torch.from_numpy(np.load(std_fp)).float().view(1, feat_dim, 1).to(device_name)\n",
    "    \n",
    "    vocoder_config_fp = './melgan/args.yml'\n",
    "    vocoder_config = read_yaml(vocoder_config_fp)\n",
    "\n",
    "    n_mel_channels = vocoder_config.n_mel_channels\n",
    "    ngf = vocoder_config.ngf\n",
    "    n_residual_layers = vocoder_config.n_residual_layers\n",
    "\n",
    "    vocoder = Generator_melgan(n_mel_channels, ngf, n_residual_layers).to(device_name)\n",
    "    vocoder.eval()\n",
    "\n",
    "    vocoder_param_fp = os.path.join('./melgan', MELGAN_MODEL_NAME)\n",
    "    vocoder.load_state_dict(torch.load(vocoder_param_fp, map_location=torch.device(device_name)), strict=False)\n",
    "\n",
    "    return vocoder, v_mean, v_std\n",
    "VOCODER, V_MEAN, V_STD = load_vocoder(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocode(sample, vocoder=VOCODER, v_mean=V_MEAN, v_std=V_STD):\n",
    "    de_norm = sample.squeeze(0) * v_std + v_mean\n",
    "    audio_output = vocoder(de_norm)\n",
    "    return audio_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "prev_sample_z = None\n",
    "prev_center_z = None\n",
    "\n",
    "def get_center_z(x, y, device):\n",
    "    assert x >= 0 and x <= 1.0\n",
    "    assert y >= 0 and y <= 1.0\n",
    "\n",
    "    z = (1-x) * (1-y) * z_presets[0] + x * (1-y) * z_presets[1] + (1-x) * y * z_presets[2] + x * y * z_presets[3]\n",
    "    z = torch.tensor(z, device=device).double()\n",
    "    print(z.shape)\n",
    "    z = z.repeat(n_samples, 1)\n",
    "    print(z.shape)\n",
    "    return z    \n",
    "\n",
    "\n",
    "def generate(g_ema, device, mean_latent, center_z = None, truncation=TRUNCATION, prev_coef=0.0):\n",
    "    global prev_sample_z, prev_center_z\n",
    "\n",
    "    with torch.no_grad():\n",
    "        g_ema.eval()\n",
    "        if center_z is None:\n",
    "\n",
    "            # random init\n",
    "            if prev_sample_z is None or prev_coef < 0.0:\n",
    "                sample_z = torch.randn(1, N_LATENT, device=device)\n",
    "                prev_center_z = sample_z.squeeze()\n",
    "                sample_z = sample_z.repeat(n_samples, 1)\n",
    "            # continuous\n",
    "            else:\n",
    "                sample_z = prev_sample_z + torch.randn(n_samples, N_LATENT, device=device) * prev_coef\n",
    "                prev_center_z = sample_z.mean(0)\n",
    "        else:\n",
    "            sample_z = center_z + torch.randn(n_samples, N_LATENT, device=device) * prev_coef\n",
    "            prev_center_z = center_z\n",
    "        sample_z = sample_z.float()\n",
    "        \n",
    "        prev_sample_z = sample_z\n",
    "        sample, _ = g_ema([sample_z], truncation=truncation, truncation_latent=mean_latent)\n",
    "      \n",
    "#        np.save(f'./tmp/{epoch}/mel_80_320/{i}.npy', sample.squeeze().data.cpu().numpy())\n",
    "#        print(sample)\n",
    "\n",
    "        randid = random.randint(0, 10000)\n",
    "        imagepath = f'/tmp/img_{randid}.png'\n",
    "        utils.save_image(sample, imagepath, nrow=1, normalize=True, range=(-1, 1))\n",
    "    \n",
    "        # for i in range(n_samples):\n",
    "        channels = []\n",
    "        filepath = f'/tmp/gem_{randid}.wav'\n",
    "        for i in range(n_samples):\n",
    "            audio_output = vocode(sample[i])\n",
    "            audio_output = audio_output.squeeze().detach().cpu().numpy() \n",
    "\n",
    "            channel = AudioSegment( (audio_output*np.iinfo(np.int16).max).astype(\"int16\").tobytes(), sample_width=2, # 16 bit \n",
    "                    frame_rate=SR, channels=1)\n",
    "            channels.append(channel)\n",
    "\n",
    "            filepath_ = f'/tmp/gem_{randid}_{i}.wav'\n",
    "            sf.write(filepath_, audio_output, SR)\n",
    "\n",
    "        multich = AudioSegment.from_mono_audiosegments(*channels)\n",
    "        multich.export(filepath, format=\"wav\")\n",
    "        # outputs = torch.vstack(outputs)\n",
    "        # print(sample.shape, outputs.shape)\n",
    "#            filepath = f'/tmp/gem_{randid}_{i}.wav'\n",
    "#            sf.write(filepath, audio_output.squeeze().detach().cpu().numpy(), SR)\n",
    "#            filepaths.append(filepath)\n",
    "        return filepath, imagepath\n",
    "            # sf.write(f'{args.store_path}/{epoch}/{i}.wav', audio_output.squeeze().detach().cpu().numpy(), sr)\n",
    "            # print('generate {}th wav file'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_z = coord_to_z(0, 0)\n",
    "# print(sample_z[:10], z_coord[0][:10])\n",
    "# sample_z = coord_to_z(0, 1)\n",
    "# print(sample_z[:10], z_coord[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample_z = coord_to_z(0, 0.5)\n",
    "# audio_output = generate(generator, device_name, mean_latent, CHECKPOINT, sample_z=sample_z)\n",
    "# audio_output.shape\n",
    "\n",
    "# Audio(audio_output, sr=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving on ('127.0.0.1', 10015)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nao/anaconda3/envs/looptest/lib/python3.8/site-packages/torchvision/utils.py:63: UserWarning: The parameter 'range' is deprecated since 0.12 and will be removed in 0.14. Please use 'value_range' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nao/Documents/GitHub/LoopTest/generate_audio.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nao/Documents/GitHub/LoopTest/generate_audio.ipynb#ch0000008?line=44'>45</a>\u001b[0m server \u001b[39m=\u001b[39m osc_server\u001b[39m.\u001b[39mThreadingOSCUDPServer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nao/Documents/GitHub/LoopTest/generate_audio.ipynb#ch0000008?line=45'>46</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m10015\u001b[39m), dispatcher)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nao/Documents/GitHub/LoopTest/generate_audio.ipynb#ch0000008?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mServing on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(server\u001b[39m.\u001b[39mserver_address))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nao/Documents/GitHub/LoopTest/generate_audio.ipynb#ch0000008?line=47'>48</a>\u001b[0m server\u001b[39m.\u001b[39;49mserve_forever()\n",
      "File \u001b[0;32m~/anaconda3/envs/looptest/lib/python3.8/socketserver.py:232\u001b[0m, in \u001b[0;36mBaseServer.serve_forever\u001b[0;34m(self, poll_interval)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/socketserver.py?line=228'>229</a>\u001b[0m selector\u001b[39m.\u001b[39mregister(\u001b[39mself\u001b[39m, selectors\u001b[39m.\u001b[39mEVENT_READ)\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/socketserver.py?line=230'>231</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__shutdown_request:\n\u001b[0;32m--> <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/socketserver.py?line=231'>232</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(poll_interval)\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/socketserver.py?line=232'>233</a>\u001b[0m     \u001b[39m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/socketserver.py?line=233'>234</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__shutdown_request:\n",
      "File \u001b[0;32m~/anaconda3/envs/looptest/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/nao/anaconda3/envs/looptest/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pythonosc import dispatcher\n",
    "from pythonosc import osc_server, udp_client\n",
    "import os, random\n",
    "\n",
    "client = udp_client.SimpleUDPClient('127.0.0.1', 10018)\n",
    "\n",
    "def generate_continuous(unused_addr, prev_coef):\n",
    "#    try:\n",
    "    audiopath, imagepath = generate(generator, device_name, mean_latent, center_z=None, prev_coef=prev_coef) # random sample\n",
    "    client.send_message(\"/generated\", (audiopath, imagepath))\n",
    "\n",
    "def generate_random(unused_addr):\n",
    "#    try:\n",
    "    audiopath, imagepath = generate(generator, device_name, mean_latent, center_z=None, prev_coef=-1) # random sample\n",
    "    client.send_message(\"/generated\", (audiopath, imagepath)) # init both R and L\n",
    "    client.send_message(\"/generated\", (audiopath, imagepath))\n",
    "\n",
    "def generate_xy(unused_addr, x, y, coef):\n",
    "#    try:\n",
    "    z_center = get_center_z(x, y, device_name)\n",
    "    audiopath, imagepath = generate(generator, device_name, mean_latent, center_z=z_center, prev_coef=coef) # random sample\n",
    "    client.send_message(\"/generated\", (audiopath, imagepath))\n",
    "\n",
    "def generate_z(unused_addr, *args):\n",
    "    z = torch.tensor(np.array(args).reshape(1,-1), device=device_name)\n",
    "    z = z.repeat(n_samples, 1)\n",
    "    audiopath, imagepath = generate(generator, device_name, mean_latent, center_z=z, prev_coef=0.2) # random sample\n",
    "    client.send_message(\"/generated\", (audiopath, imagepath))   \n",
    "\n",
    "def store_z(unused_addr, idx):\n",
    "    if prev_center_z is not None:\n",
    "        z_presets[idx] = prev_center_z.cpu().numpy().reshape(1,-1)\n",
    "        np.savez(STOREDZ_PATH, z_presets=z_presets)\n",
    "        client.send_message(\"/stored\", 1)\n",
    "\n",
    "#    except Exception as exp:\n",
    "#        print(\"Error in /find_loops\", exp)        \n",
    "dispatcher = dispatcher.Dispatcher()\n",
    "dispatcher.map(\"/generate\", generate_continuous)\n",
    "dispatcher.map(\"/generate_random\", generate_random)\n",
    "dispatcher.map(\"/generate_xy\", generate_xy)\n",
    "dispatcher.map(\"/generate_z\", generate_z)\n",
    "dispatcher.map(\"/store_z\", store_z)\n",
    "\n",
    "server = osc_server.ThreadingOSCUDPServer(\n",
    "    ('localhost', 10015), dispatcher)\n",
    "print(\"Serving on {}\".format(server.server_address))\n",
    "server.serve_forever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70899268a59b9e14302f4ecef5a4c87b2b8a3484e36d1ae41be0a1619eb013cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('looptest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
